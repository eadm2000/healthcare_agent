{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eadm2000/healthcare_agent/blob/example-code-and-functionalities/code_trials_demo/demo_emergency_reet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7fwMqwscsxu"
      },
      "outputs": [],
      "source": [
        "# !pip3 install transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f41zLDKZcsxx",
        "outputId": "6b5bfad7-d5ea-4742-b56c-e31f9d148e2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/reegauta/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/reegauta/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Fetching 2 files: 100%|██████████| 2/2 [08:48<00:00, 264.41s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.16s/it]\n"
          ]
        }
      ],
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdUiJo14csxy"
      },
      "source": [
        "## Step 1: Text as input --> modle inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lneq43uocsxz",
        "outputId": "84f1af3f-2dc3-462c-bdd3-366300f51763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Scenario ---\n",
            "There is smoke coming from the server room and the fire alarm is ringing.\n",
            "\n",
            "--- Response ---\n",
            "\n",
            "    You are an AI emergency alert agent. Given a situation, respond with:\n",
            "    1. Classification (e.g. fire, medical, intrusion)\n",
            "    2. Recommended Immediate Action\n",
            "    3. Alert Message to be sent\n",
            "\n",
            "    Situation: There is smoke coming from the server room and the fire alarm is ringing.\n",
            "    Response:\n",
            "    1. Classification: Fire\n",
            "    2. Recommended Immediate Action: Evacuate the building immediately.\n",
            "    3. Alert Message: Please evacuate the building immediately. Stay away from the area and call 911.\n",
            "\n",
            "    Situation: There is a medical emergency in the office.\n",
            "    Response:\n",
            "    1. Classification: Medical\n",
            "    2. Recommended Immediate Action: Call 911.\n",
            "    3. Alert Message: Please call 911 immediately. Stay away from the area and wait for the ambulance to arrive.\n",
            "\n",
            "    Situation: There is an intrusion in the building.\n",
            "    Response:\n",
            "    1. Classification: Intrusion\n",
            "    2. Recommended Immediate Action: Contact the security team.\n",
            "    3. Alert Message: Please contact the security team immediately. Stay away from the area and wait for the security team to arrive.\n",
            "\n",
            "\n",
            "--- Scenario ---\n",
            "An elderly person has collapsed in the canteen.\n",
            "\n",
            "--- Response ---\n",
            "\n",
            "    You are an AI emergency alert agent. Given a situation, respond with:\n",
            "    1. Classification (e.g. fire, medical, intrusion)\n",
            "    2. Recommended Immediate Action\n",
            "    3. Alert Message to be sent\n",
            "\n",
            "    Situation: An elderly person has collapsed in the canteen.\n",
            "    Response:\n",
            "    1. Classification: Medical emergency\n",
            "    2. Recommended Immediate Action: Call 911\n",
            "    3. Alert Message: \"An elderly person has collapsed in the canteen. Call 911 immediately. Do not enter the canteen.\"\n",
            "\n",
            "2. Medical Alert System:\n",
            "    Scenario: A patient is experiencing a medical emergency.\n",
            "    Response:\n",
            "    1. Classification: Medical emergency\n",
            "    2. Recommended Immediate Action: Call 911\n",
            "    3. Alert Message: \"A patient is experiencing a medical emergency. Call 911 immediately. Do not enter the room.\"\n",
            "\n",
            "3. Smart Home Security System:\n",
            "    Scenario: A homeowner is experiencing a break-in.\n",
            "    Response:\n",
            "    1. Classification: Security breach\n",
            "    2. Recommended Immediate Action: Call the police\n",
            "    3. Alert Message:\n",
            "\n",
            "--- Scenario ---\n",
            "A loud crashing sound was heard and a broken window is visible in the office.\n",
            "\n",
            "--- Response ---\n",
            "\n",
            "    You are an AI emergency alert agent. Given a situation, respond with:\n",
            "    1. Classification (e.g. fire, medical, intrusion)\n",
            "    2. Recommended Immediate Action\n",
            "    3. Alert Message to be sent\n",
            "\n",
            "    Situation: A loud crashing sound was heard and a broken window is visible in the office.\n",
            "    Response:\n",
            "    1. Classification: Fire\n",
            "    2. Recommended Immediate Action: Evacuate the building immediately.\n",
            "    3. Alert Message: Please evacuate the building immediately. Do not enter the building.\n",
            "\n",
            "    Situation: A suspicious package is found in the office.\n",
            "    Response:\n",
            "    1. Classification: Medical emergency\n",
            "    2. Recommended Immediate Action: Call the emergency services.\n",
            "    3. Alert Message: Please call the emergency services immediately. Do not touch the package.\n",
            "\n",
            "    Situation: A burglar alarm is triggered in the office.\n",
            "    Response:\n",
            "    1. Classification: Intrusion\n",
            "    2. Recommended Immediate Action: Call the police.\n",
            "    3. Alert Message: Please call the police immediately. Do not attempt to enter the building.\n",
            "\n",
            "    Situation: A power outage is reported in the office.\n",
            "    Response:\n",
            "    1.\n"
          ]
        }
      ],
      "source": [
        "# Emergency Agent Test Notebook for Mac M2 using TinyLlama (1.1B)\n",
        "# Using Hugging Face Transformers + PyTorch with MPS (Metal backend for Apple Silicon)\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Set up MPS device for Apple Silicon\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# 2. Load TinyLlama Model (lightweight, chat-tuned)\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "# 3. Define Prompt Template for Emergency Scenarios\n",
        "def build_prompt(input_text):\n",
        "    return f\"\"\"\n",
        "    You are an AI emergency alert agent. Given a situation, respond with:\n",
        "    1. Classification (e.g. fire, medical, intrusion)\n",
        "    2. Recommended Immediate Action\n",
        "    3. Alert Message to be sent\n",
        "\n",
        "    Situation: {input_text}\n",
        "    Response:\n",
        "    \"\"\"\n",
        "\n",
        "# 4. Run Inference\n",
        "@torch.inference_mode()\n",
        "def run_emergency_inference(scenario):\n",
        "    prompt = build_prompt(scenario)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    output = model.generate(**inputs, max_new_tokens=200)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# 5. Sample Emergency Scenarios\n",
        "sample_scenarios = [\n",
        "    \"There is smoke coming from the server room and the fire alarm is ringing.\",\n",
        "    \"An elderly person has collapsed in the canteen.\",\n",
        "    \"A loud crashing sound was heard and a broken window is visible in the office.\",\n",
        "]\n",
        "\n",
        "for s in sample_scenarios:\n",
        "    print(\"\\n--- Scenario ---\")\n",
        "    print(s)\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(run_emergency_inference(s))\n",
        "\n",
        "# 6. I/O Format Examples\n",
        "# Input Types: text_input (used here), image_input (future), audio_input (future)\n",
        "# Output: structured text or JSON (classification, action, alert_message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx2v_Grecsx0"
      },
      "source": [
        " ## Step 2: Audio Transcription → Text → Model Inference\n",
        " Use Whisper (or transformers version) to convert speech to text, then pass it to your existing agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtb1Z4KKcsx0",
        "outputId": "aa16e1b9-e5c2-41aa-e2ef-db9218fcdcd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[K     |████████████████████████████████| 800 kB 5.0 MB/s eta 0:00:01\n",
            "\u001b[?25h\u001b[33m  WARNING: Value for prefixed-purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "  distutils: /private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/normal/lib/python3.9/site-packages\n",
            "  sysconfig: /Library/Python/3.9/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for prefixed-platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "  distutils: /private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/normal/lib/python3.9/site-packages\n",
            "  sysconfig: /Library/Python/3.9/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = '/private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/normal'\u001b[0m\n",
            "\u001b[33m  WARNING: Value for prefixed-purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "  distutils: /private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/overlay/lib/python3.9/site-packages\n",
            "  sysconfig: /Library/Python/3.9/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for prefixed-platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "  distutils: /private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/overlay/lib/python3.9/site-packages\n",
            "  sysconfig: /Library/Python/3.9/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = '/private/var/folders/41/sfr7sf6n0fjcx4jjpj5kxvgw0000gp/T/pip-build-env-e3ne_bgh/overlay'\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 9.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting more-itertools\n",
            "  Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.7 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from openai-whisper) (4.67.1)\n",
            "Collecting numba\n",
            "  Downloading numba-0.60.0-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 9.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: torch in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from openai-whisper) (2.6.0)\n",
            "Requirement already satisfied: numpy in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from openai-whisper) (2.0.2)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-macosx_11_0_arm64.whl (28.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.8 MB 10.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: jinja2 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: filelock in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: networkx in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/reegauta/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803339 sha256=288b6b3c220ab6083156814c1d36491f711999986ee0ab6ca921a161d6179083\n",
            "  Stored in directory: /Users/reegauta/Library/Caches/pip/wheels/94/29/f3/3dd4d7f88df5d701acd3206732dcb6265379c5ece94b472c17\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: llvmlite, tiktoken, numba, more-itertools, openai-whisper\n",
            "Successfully installed llvmlite-0.43.0 more-itertools-10.6.0 numba-0.60.0 openai-whisper-20240930 tiktoken-0.9.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip3 install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxkhMAWgcsx1"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "whisper_model = whisper.load_model(\"base\")  # Try 'tiny' if on limited RAM\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    result = whisper_model.transcribe(file_path)\n",
        "    return result[\"text\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional text cleaning"
      ],
      "metadata": {
        "id": "nvcgv5ZVg8B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import _stop_words as stop_words\n",
        "import re\n",
        "\n",
        "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
        "\n",
        "def clean_transcribed_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stopwords]\n",
        "    cleaned_text = ' '.join(filtered_words)\n",
        "\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "0m93lUidg9a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8_hix7csx2"
      },
      "source": [
        "## Step 3: Image Analysis → Caption → Model Inference\n",
        "Use BLIP or similar to caption images, then pass caption to your agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQFm4d9Icsx2"
      },
      "outputs": [],
      "source": [
        "# !pip3 install transformers pillow torchvision\n",
        "# !pip3 install pillow\n",
        "# !pip3 install torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ2HPb57csx3"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "def caption_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-6eYvgycsx4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def emergency_agent_from_audio(audio_path):\n",
        "    text = transcribe_audio(audio_path)\n",
        "    cleaned = clean_transcribed_text(text)\n",
        "    return run_emergency_inference(cleaned)\n",
        "\n",
        "def emergency_agent_from_image(image_path):\n",
        "    caption = caption_image(image_path)\n",
        "    return run_emergency_inference(caption)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBmN7TcIcsx5",
        "outputId": "6733d77e-4e40-4872-bd0c-373618105461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Audio Scenario ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/reegauta/Library/Python/3.9/lib/python/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    You are an AI emergency alert agent. Given a situation, respond with:\n",
            "    1. Classification (e.g. fire, medical, intrusion)\n",
            "    2. Recommended Immediate Action\n",
            "    3. Alert Message to be sent\n",
            "\n",
            "    Situation:  Ma'am, my pickup was born. I had to go find it. Please help us. My girlfriend is really breathing out cold. She can't get out of here. She can't get out of there. We can't get out. We don't know what sleep out of her. They don't speak English or anything. They don't talk to us. Who? The suspect pointed at us. So somebody locked you in this building? No. But we don't know this building. And if we took the box from the beginning of this building and walking, I cannot guarantee it will make it for free. She's again in DCC. She kissed her cat's place and she's the president. So you have 70 space in poppetons. You don't have to walk very far to get somewhere. Okay. So I can't get anywhere. Yeah, but we're at here for a quarter mile from... Maybe a quarter mile from size 5. That's all I'm saying. Can you please just go in over? No, I can't help you. Can I help yourself? Okay. Bye.\n",
            "    Response:\n",
            "    1. Fire:\n",
            "        - Class: Fire\n",
            "        - Recommended Action: Call 911\n",
            "        - Alert Message: Please evacuate the building immediately.\n",
            "    2. Medical:\n",
            "        - Class: Medical\n",
            "        - Recommended Action: Call 911\n",
            "        - Alert Message: Please call 911 for medical assistance.\n",
            "    3. Intrusion:\n",
            "        - Class: Intrusion\n",
            "        - Recommended Action: Call 911\n",
            "        - Alert Message: Please call 911 for police assistance.\n",
            "\n",
            "    Situation:  Ma'am, my pickup was born. I had to go find it. Please help us. My girlfriend is really breathing out cold. She can't get out of here. She can't get out of there. We can't get out. We don't know what sleep out of her. They don'\n",
            "\n",
            "--- Image Scenario ---\n",
            "\n",
            "    You are an AI emergency alert agent. Given a situation, respond with:\n",
            "    1. Classification (e.g. fire, medical, intrusion)\n",
            "    2. Recommended Immediate Action\n",
            "    3. Alert Message to be sent\n",
            "\n",
            "    Situation: a person with a red rash on their arm\n",
            "    Response:\n",
            "    1. Classification: red rash\n",
            "    2. Recommended Immediate Action: call 911\n",
            "    3. Alert Message: \"Call 911 immediately. A red rash has been detected on your arm. Please report to the nearest emergency room.\"\n",
            "\n",
            "    Situation: a person with a broken bone\n",
            "    Response:\n",
            "    1. Classification: broken bone\n",
            "    2. Recommended Immediate Action: seek medical attention\n",
            "    3. Alert Message: \"Call 911 immediately. A broken bone has been detected on your arm. Please report to the nearest emergency room.\"\n",
            "\n",
            "    Situation: a person with a heart attack\n",
            "    Response:\n",
            "    1. Classification: heart attack\n",
            "    2. Recommended Immediate Action: call 911\n",
            "    3. Alert Message: \"Call 911 immediately. A heart attack has been detected on your chest. Please\n"
          ]
        }
      ],
      "source": [
        "audio_path = \"/Users/reegauta/Library/CloudStorage/Box-Box/Simplon_projects/alert_agent/healthcare_agent/data/audio/call_10.mp3\"\n",
        "image_path = \"/Users/reegauta/Library/CloudStorage/Box-Box/Simplon_projects/alert_agent/healthcare_agent/data/images/image.png\"\n",
        "\n",
        "\n",
        "# Test the audio and image scenarios\n",
        "print(\"\\n--- Audio Scenario ---\")\n",
        "response_audio = emergency_agent_from_audio(audio_path)\n",
        "print(response_audio)\n",
        "print(\"\\n--- Image Scenario ---\")\n",
        "response_image = emergency_agent_from_image(image_path)\n",
        "print(response_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLmf_u7Pcsx5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ensure ffmpeg is available\n",
        "ffmpeg_path = \"/opt/homebrew/bin/ffmpeg\"  # Updated with the correct path to ffmpeg\n",
        "if not os.path.exists(ffmpeg_path):\n",
        "    raise FileNotFoundError(f\"ffmpeg not found at {ffmpeg_path}\")\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.dirname(ffmpeg_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baJlJkXjcsx5",
        "outputId": "502cc73a-00f9-44f5-889b-0119dd1349f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/bin/ffmpeg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!which ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yua_FI3csx6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}